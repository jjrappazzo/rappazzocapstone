[
  {
    "objectID": "basic-example.html",
    "href": "basic-example.html",
    "title": "United States Car Accident Project",
    "section": "",
    "text": "Binary Response Model \n Linear Regression \n Lasso Regression \n Ridge Regression \n Ordinal Logit Regression \n Decision Tree \n Random Forest \n Artificial Neural Network"
  },
  {
    "objectID": "basic-example.html#overview-of-modeling-techniques---me",
    "href": "basic-example.html#overview-of-modeling-techniques---me",
    "title": "United States Car Accident Project",
    "section": "",
    "text": "Binary Response Model \n Linear Regression \n Lasso Regression \n Ridge Regression \n Ordinal Logit Regression \n Decision Tree \n Random Forest \n Artificial Neural Network"
  },
  {
    "objectID": "basic-example.html#preparing-data-for-machine-learning",
    "href": "basic-example.html#preparing-data-for-machine-learning",
    "title": "United States Car Accident Project",
    "section": "2.1 Preparing Data For Machine Learning",
    "text": "2.1 Preparing Data For Machine Learning\n\naccident_12var &lt;- accident_raw %&gt;% \n  select(Severity,State, `Temperature(F)`, `Humidity(%)`, `Visibility(mi)`, `Wind_Speed(mph)`, Weather_Condition, `Precipitation(in)`, Crossing, Junction, Traffic_Signal, Sunrise_Sunset)\n\ncolnames(accident_12var) &lt;- gsub(\"\\\\)|\\\\%|\\\\(\", \".\", colnames(accident_12var))\n\n\nlibrary(caret)\nlibrary(recipes)\nlibrary(dplyr)\n\n# Split the data into training and testing sets\nset.seed(2)\ntrain_indices &lt;- createDataPartition(accident_12var$Severity, p = 0.8, list = FALSE)\ntrain_set &lt;- accident_12var[train_indices, ]\ntest_set &lt;- accident_12var[-train_indices, ]\n\n\n# TRAIN SET\n\n# Make a copy of the train set\ncopied_traindata &lt;- data.frame(train_set)\n\n# Add an id column to copied_traindata\ncopied_traindata &lt;- copied_traindata %&gt;% mutate(id = row_number())\n\n# Separate Label from Feature\naccident &lt;- select(copied_traindata, -Severity) # drop Severity column\nlabel &lt;- copied_traindata$Severity # select Severity column\n\n# Separate Numerical from Categorical\naccident_num &lt;- accident %&gt;% \n  select(id, Temperature.F., Humidity..., Visibility.mi., Wind_Speed.mph., Precipitation.in.)\n\naccident_cat &lt;- accident %&gt;% \n  select(id, State, Weather_Condition, Crossing, Junction, Traffic_Signal, Sunrise_Sunset)\n\n# Define numeric and categorical attributes\nnum_attribs &lt;- names(accident_num)[2:6]\ncat_attribs &lt;- names(accident_cat)[2:7]\n\n# Define preprocessing pipelines\nnum_pipeline &lt;- recipe(~., data = accident_num) %&gt;%\n  step_impute_median(all_numeric(), -has_role(\"id\")) %&gt;%\n  step_center(all_numeric(), -has_role(\"id\")) %&gt;%\n  step_scale(all_numeric(), -has_role(\"id\"))\n\ncat_pipeline &lt;- recipe(~., data = accident_cat) %&gt;%\n  step_dummy(all_nominal())\n\n# Merge the preprocessed numerical and categorical features into a single dataset\n\naccident &lt;- accident %&gt;% rename(Index = id) \n\ndf1 &lt;- mutate(num_pipeline %&gt;% prep() %&gt;% bake(new_data = NULL), join_key = \"Index\")\ndf2 &lt;- mutate(cat_pipeline %&gt;% prep() %&gt;% bake(new_data = NULL), join_key = \"Index\")\n\naccident_prepared &lt;- accident %&gt;% \n  select(-one_of(c(cat_attribs, num_attribs)))\n\naccident_prepared &lt;- cbind(accident_prepared, df1,df2)\n\n\n\naccident_prepared &lt;- accident_prepared %&gt;% \n  distinct()\n\naccident_prepared &lt;- select(accident_prepared, -c(\"Index\", \"id\", \"join_key\", \"id.1\", \"join_key.1\"))\n\n\n\n\n\n\n#TEST SET\n# Make a copy of the test set\ncopied_testdata &lt;- data.frame(test_set)\n\n# Add an id column to copied_testdata\ncopied_testdata &lt;- copied_testdata %&gt;% mutate(id = row_number())\n\n# Separate Label from Feature\naccident_test &lt;- select(copied_testdata, -Severity) # drop Severity column\nlabel_test &lt;- copied_testdata$Severity # select Severity column\n\n# Separate Numerical from Categorical\naccident_num_test &lt;- copied_testdata %&gt;% \n  select(Temperature.F., Humidity..., Visibility.mi., Wind_Speed.mph., Precipitation.in.)\n\naccident_cat_test &lt;- copied_testdata %&gt;% \n  select(State, Weather_Condition, Crossing, Junction, Traffic_Signal, Sunrise_Sunset)\n\n# Define numeric and categorical attributes\nnum_attribs &lt;- names(accident_num_test)[1:6]\ncat_attribs &lt;- names(accident_cat_test)[1:7]\n\n# Define preprocessing pipelines\nnum_pipeline &lt;- recipe(~., data = accident_num_test) %&gt;%\n  step_impute_median(all_numeric(), -has_role(\"id\")) %&gt;%\n  step_center(all_numeric(), -has_role(\"id\")) %&gt;%\n  step_scale(all_numeric(), -has_role(\"id\"))\n\ncat_pipeline &lt;- recipe(~., data = accident_cat_test) %&gt;%\n  step_dummy(all_nominal())\n\n# Merge the preprocessed numerical and categorical features into a single dataset\n\ncopied_testdata &lt;- copied_testdata %&gt;% rename(Index = id) \n\ndf1 &lt;- mutate(num_pipeline %&gt;% prep() %&gt;% bake(new_data = NULL), join_key = \"Index\")\ndf2 &lt;- mutate(cat_pipeline %&gt;% prep() %&gt;% bake(new_data = NULL), join_key = \"Index\")\n\naccident_prepared_test &lt;- accident_test %&gt;% \n  select(-one_of(c(cat_attribs, num_attribs)))\n\naccident_prepared_test &lt;- cbind(accident_prepared_test, df1,df2)\n\n\n\naccident_prepared_test &lt;- accident_prepared_test %&gt;% \n  distinct()\n\naccident_prepared_test &lt;- select(accident_prepared_test, -c(\"id\", \"join_key\", \"join_key.1\"))\n\naccident_prepared_test$Weather_Condition_Blowing.Dust...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Clear &lt;- 0\naccident_prepared_test$Weather_Condition_Blowing.Snow...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Freezing.Drizzle &lt;- 0\naccident_prepared_test$Weather_Condition_Heavy.Drizzle &lt;- 0\naccident_prepared_test$Weather_Condition_Heavy.Sleet &lt;- 0\naccident_prepared_test$Weather_Condition_Heavy.Snow...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Light.Freezing.Rain...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Light.Ice.Pellets &lt;- 0\naccident_prepared_test$Weather_Condition_Light.Thunderstorms.and.Rain &lt;- 0\naccident_prepared_test$Weather_Condition_Sleet &lt;- 0\naccident_prepared_test$Weather_Condition_Thunder...Wintry.Mix &lt;- 0\naccident_prepared_test$Weather_Condition_Smoke...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Thunder.and.Hail &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Light.Snow.Shower &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust...Windy &lt;- 0\naccident_prepared_test$Weather_Condition_Widespread.Dust...Windy &lt;- 0"
  },
  {
    "objectID": "basic-example.html#linear-regression",
    "href": "basic-example.html#linear-regression",
    "title": "United States Car Accident Project",
    "section": "3.1 Linear Regression",
    "text": "3.1 Linear Regression\n\n# Fit the linear regression model\nlin_reg &lt;- lm(label ~ ., data = accident_prepared)\n\n# Use the model to predict the response variable using the test data\ny_pred &lt;- predict(lin_reg, newdata = accident_prepared_test)\n\n# Calculate the residuals\nresiduals &lt;- y_pred - label_test\n\n# Calculate the squared errors\nsquared_errors &lt;- residuals^2\n\n# Calculate the mean squared error\nmse &lt;- mean(squared_errors)\n\n# Print the MSE\ncat(\"MSE:\", mse)\n## MSE: 0.1324914"
  },
  {
    "objectID": "basic-example.html#ridge-regression",
    "href": "basic-example.html#ridge-regression",
    "title": "United States Car Accident Project",
    "section": "3.2 Ridge Regression",
    "text": "3.2 Ridge Regression\n\n#ridge regression\n\nlibrary(glmnet)\n\n# Separate the predictor variables from the response variable\ny &lt;- label\nX &lt;- as.matrix(select(accident_prepared, -label))\n\n# Define the lambda sequence for ridge regression\nlambda_seq &lt;- 10^seq(10, -2, length = 100)\n\n# Perform cross-validated ridge regression\nridge_fit &lt;- cv.glmnet(X, y, alpha = 0, lambda = lambda_seq)\n\n# Plot the cross-validation results\nplot(ridge_fit)\n\n\n\n\nridge_coef &lt;- coef(ridge_fit)[-1]\n\ny_pred &lt;- predict(ridge_fit, newx = X)\n\nmse &lt;- mean((y - y_pred)^2)\n\n\n# Print the MSE\ncat(\"MSE:\", mse)\n## MSE: 0.1341102"
  },
  {
    "objectID": "basic-example.html#lasso-regression",
    "href": "basic-example.html#lasso-regression",
    "title": "United States Car Accident Project",
    "section": "3.3 Lasso Regression",
    "text": "3.3 Lasso Regression\n\nx &lt;- model.matrix(~ ., data = accident_prepared) \ny &lt;- label\n\n# Fit a Lasso regression with cross-validation\nlasso_model &lt;- cv.glmnet(x, y, alpha = 1) \n\nextra_columns &lt;- setdiff(colnames(accident_prepared_test), colnames(accident_prepared))\n\naccident_prepared_test &lt;- accident_prepared_test %&gt;%\n                          select(-one_of(extra_columns))\n\n\n# Predict the response variable using the test data\nx_test &lt;- model.matrix(~ ., data = accident_prepared_test) \ny_pred &lt;- predict(lasso_model, newx = x_test)\n\n# Calculate the MSE\nmse &lt;- mean((y_pred - label_test)^2)\n\n# Print the MSE\ncat(\"MSE:\", mse)\n## MSE: 0.134835\n\n\nplot(lasso_model)"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html",
    "href": "DANL310_midterm-spring-2023-a.html",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "",
    "text": "library(knitr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(socviz)\nlibrary(ggthemes)\nlibrary(hrbrthemes)\nlibrary(gapminder)\nlibrary(stargazer)\n\n\nI use theme_set(theme_ipsum() + theme(strip.background =element_rect(fill=\"lightgray\"))) in the setup R code chunk with the include = FALSE option"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#loading-r-packages",
    "href": "DANL310_midterm-spring-2023-a.html#loading-r-packages",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "",
    "text": "library(knitr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(socviz)\nlibrary(ggthemes)\nlibrary(hrbrthemes)\nlibrary(gapminder)\nlibrary(stargazer)\n\n\nI use theme_set(theme_ipsum() + theme(strip.background =element_rect(fill=\"lightgray\"))) in the setup R code chunk with the include = FALSE option"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q1a",
    "href": "DANL310_midterm-spring-2023-a.html#q1a",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q1a",
    "text": "Q1a\n\nReplicate the following ggplot.\n\nUse the color #0072B2 for dots.\n\n\n\n# Set the data and filter to include only observations from 2007 and exclude Oceania\nggplot(data = filter(gapminder, year == 2007,\n                     continent != 'Oceania'),\n\n       # Set the aesthetics (x-axis and y-axis) to life expectancy and reorder countries by life expectancy\n       aes(x = lifeExp,\n           y = fct_reorder(country, lifeExp))) +\n\n  # Add a layer of points to the plot, setting the color to blue and size to 1.75\n  geom_point(color = \"#0072B2\", size = 1.75) +\n\n  # Add a layer of text labels to the plot, setting the label to life expectancy, hjust to -.25, and size to 2\n  geom_text(aes(label = lifeExp), hjust = -.25,\n            size = 2) +\n\n  # Facet the plot by continent, with y-scales free\n  facet_wrap(.~continent, scales = \"free_y\") +\n\n  # Set the x-axis label to NULL (no name) and limit the x-axis to 35-90\n  scale_x_continuous(\n    name = NULL,\n    lim = c(35, 90)\n  ) +\n\n  # Set the y-axis label to NULL (no name)\n  scale_y_discrete(name = NULL) +\n\n  # Add a title to the plot\n  labs(title = 'Life expectancy in 2007') +\n\n  # Set the theme to minimal\n  theme_minimal() +\n\n  # Customize theme elements: set the y-axis text size, the plot title size and position, and the facet strip text size and font face\n  theme(\n    axis.text.y = element_text(size = rel(.75)),\n    plot.title = element_text(size = rel(1.5),\n                              hjust = 0.5,\n                              face = 'bold'),\n    strip.text = element_text(size = rel(1.25),\n                              face = 'bold')\n  )"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q1b",
    "href": "DANL310_midterm-spring-2023-a.html#q1b",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q1b",
    "text": "Q1b\n\nMake a simple comment on the visualization result.\n\nAny comment that is not made up is okay."
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q2a",
    "href": "DANL310_midterm-spring-2023-a.html#q2a",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q2a",
    "text": "Q2a\n\nReplicate the following ggplot.\n\nThe following describes the type values:\n\nn_ot_us: Number of US tweets\nn_ot_wrld: Number of worldwide tweets\nn_rt_lk_us: Number of US retweets & likes\nn_rt_lk_wrld: Number of worldwide retweets & likes\n\nUse the colors, maroon and #428bca properly.\n\n\n\n# The following line filters the rows of the n_tweets_long data frame that have a value of \"n_ot_us\" or \"n_ot_wrld\" in the \"type\" column. \n# It then creates a new column called \"type\" that replaces \"n_ot_us\" with \"US\" and \"n_ot_wrld\" with \"Worldwide\".\nn_tweets_long1 &lt;- n_tweets_long %&gt;% \n  filter(type %in% c(\"n_ot_us\", \"n_ot_wrld\") ) %&gt;% \n  mutate(type = ifelse(type == \"n_ot_us\", \"US\", \"Worldwide\"))\n\n\n# The following line filters the rows of the n_tweets_long data frame that have a value of \"n_rt_lk_us\" or \"n_rt_lk_wrld\" in the \"type\" column. \n# It then creates a new column called \"type\" that replaces \"n_rt_lk_us\" with \"US\" and \"n_rt_lk_wrld\" with \"Worldwide\".\nn_tweets_long2 &lt;- n_tweets_long %&gt;% \n  filter(type %in% c(\"n_rt_lk_us\", \"n_rt_lk_wrld\") ) %&gt;% \n  mutate(type = ifelse(type == \"n_rt_lk_us\", \"US\", \"Worldwide\"))\n  \n\n\np2 &lt;- ggplot(mapping = aes(x = year, y = n)) +  # Create a ggplot object with the mapping of the x-axis to the \"year\" variable and y-axis to the \"n\" variable\n  geom_col(n_tweets_long1,  # Add a column chart layer with the \"n_tweets_long1\" data\n           mapping = aes(fill = type),  # Map the \"type\" variable to the fill aesthetic of the chart\n           position = 'dodge', alpha = .67) +  # Set the position of the columns to \"dodge\" and the transparency to 0.67\n  geom_line(n_tweets_long2,  # Add a line chart layer with the \"n_tweets_long2\" data\n            mapping = aes(color = type),  # Map the \"type\" variable to the color aesthetic of the chart\n            size = 1.5) +  # Set the line size to 1.5\n  geom_point(data = n_tweets_long2,  # Add a point chart layer with the \"n_tweets_long2\" data\n             size = 2,  # Set the point size to 2\n             color = 'black')  +  # Set the point color to black\n  scale_x_continuous(breaks = seq(2012, 2017, 1)) +  # Set the x-axis breaks to the sequence from 2012 to 2017 with an interval of 1\n  scale_y_continuous(label = scales::comma) +  # Format the y-axis labels using the comma function from the scales package\n  scale_color_manual(values = c('maroon', '#428bca')) +  # Manually set the color values for the color aesthetic\n  scale_fill_manual(values = c('maroon', '#428bca')) +   # Manually set the color values for the fill aesthetic\n  guides(fill = guide_legend(reverse = TRUE,  # Customize the fill legend guide by reversing the order of the legend, positioning the labels at the bottom, and setting the number of rows to 2 and the key width to 2\n                             # title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 2,\n                             nrow = 2,\n                             order = 1),\n         color = guide_legend(reverse = TRUE,  # Customize the color legend guide by reversing the order of the legend, positioning the labels at the bottom, and setting the number of rows to 2 and the key width to 2\n                             # title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 2,\n                             nrow = 2,\n                             order = 2)) +\n  labs(x = \"Year\",  # Add x-axis label \"Year\"\n       y = \"Number of Tweets, Retweets & Likes\\n (in thousand)\",  # Add y-axis label \"Number of Tweets, Retweets & Likes (in thousand)\"\n       fill = \"Tweets\",  # Add fill legend label \"Tweets\"\n       color = \"Retweets and likes\",  # Add color legend label \"Retweets and likes\"\n       caption = 'Source: Choe, \"Social Media Campaigns, Lobbying, and Climate Change Legislation:\\n Evidence from #climatechange/#globalwarming and Energy Lobbies\" (2023)') +  # Add caption with source information\n  theme_ipsum() +  # Use the 'theme_ipsum' theme from the 'ggthemes' package\n  theme(\n  axis.title.y = element_text(\n    size = rel(1.5),\n    margin = margin(t = 0, r = 20, b = 0, l = 0) # set the margin for the y axis title\n  ),\n  axis.title.x = element_text(\n    size = rel(1.5),\n    margin = margin(t = 10, r = 0, b = 0, l = 0) # set the margin for the x axis title\n  ),\n  axis.text.x = element_text(\n    size = rel(1.25) # set the font size for the x axis tick labels\n  ),\n  axis.text.y = element_text(\n    size = rel(1.25) # set the font size for the y axis tick labels\n  ),\n  legend.position = 'top', # set the position of the legend\n  legend.title = element_text(\n    size = rel(1),\n    face = 'bold',\n    hjust = .5 # set the font size, face and horizontal justification for the legend title\n  ),\n  legend.text = element_text(\n    size = rel(1) # set the font size for the legend text\n  ),\n  legend.spacing.x = unit(1.25, \"cm\"), # set the horizontal spacing between legend items\n  plot.caption = element_text(\n    size = rel(1.25),\n    hjust = .5 # set the font size and horizontal justification for the plot caption\n  )\n)\n\n\np2"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q2b.",
    "href": "DANL310_midterm-spring-2023-a.html#q2b.",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q2b.",
    "text": "Q2b.\n\nMake a simple comment on the visualization result.\n\nAny comment that is not made up is okay."
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q3a",
    "href": "DANL310_midterm-spring-2023-a.html#q3a",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q3a",
    "text": "Q3a\n\nReplicate the following ggplot.\n\nYou should calculate the proportion of Pit Bull (or Mix) for each zip code.\nYou should join data.frames properly.\nChoose the color palette from the viridis scales https://ggplot2.tidyverse.org/reference/scale_viridis.html.\nUse coord_map(projection = \"albers\", lat0 = 39, lat1 = 45).\n\n\n\n# Joining two data frames using a common variable\nnyc_zips_df &lt;- nyc_zips_df %&gt;% \n  left_join(nyc_zips_coord)\n\n# Creating a data frame of the top 5 dog breeds by count\nnyc_dogs &lt;- nyc_dog_license %&gt;%\n  group_by(breed_rc) %&gt;% \n  summarise(N = n()) %&gt;% \n  filter(dense_rank(-N)&lt;=5)\n\n# Creating a data frame of dog breed frequency and percentage by zip code for the top 5 breeds\nnyc_fb &lt;- nyc_dog_license %&gt;%\n  group_by(zip_code, breed_rc) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(freq = n / sum(n),\n         pct = round(freq*100, 2)) %&gt;%\n  filter(breed_rc %in% nyc_dogs$breed_rc )\n\n\n# theme_nymap &lt;- function(base_size=9, base_family=\"\") {\n#   require(grid)\n#   theme_bw(base_size=base_size, base_family=base_family) %+replace%\n#     theme(axis.line=element_blank(),\n#           axis.text=element_blank(),\n#           axis.ticks=element_blank(),\n#           axis.title=element_blank(),\n#           panel.background=element_blank(),\n#           panel.border=element_blank(),\n#           panel.grid=element_blank(),\n#           panel.spacing=unit(0, \"lines\"),\n#           plot.background=element_blank(),\n#     )\n# }\n\n\n# Create a map of New York City zip codes colored by the share of Pit Bull dogs \n# and their mixes out of all licensed dogs, based on licensing data\nfb_map &lt;- nyc_zips_df %&gt;% \n  left_join(nyc_fb)\n\n# Filter for Pit Bull breeds and plot the map\nfilter(fb_map, breed_rc %in% c('Pit Bull (or Mix)')) %&gt;% \n  ggplot(mapping = aes(x = X, y = Y, \n                       fill = pct,\n                       group = zip_code)) +\n  geom_polygon(color = \"gray80\", \n               size = 0.1) +    # draw the zip code polygons\n  scale_fill_viridis_c(option = \"inferno\",\n                       breaks = seq(0,24,2)) +  # set the color scale for Pit Bull share\n  labs(fill = \"Pit Bull's Share of All Licensed Dogs (%)\",\n       title = \"New York City's Pit Bull\",\n       subtitle = \"By Zip Code. Based on Licensing Data\") +  # set the map title and legend title\n  theme_map() +  # set the map theme\n  theme(legend.justification = c(.5,.5),\n        legend.position = 'top',\n        legend.direction = \"horizontal\",\n        legend.text = element_text(size= rel(1.25)),\n        legend.title = element_text(size= rel(1.25),\n                                face = 'bold',\n                                hjust = .5),\n        plot.title = element_text(hjust = .5,\n                                  vjust = .5,\n                                  face = 'bold',\n                                  size = rel(2.25)),\n        plot.subtitle = element_text(hjust = .5,\n                                     vjust = .5,\n                                     size = rel(1.25))) +  # customize the theme of the plot\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +  # set the map projection\n  guides(fill = guide_legend(title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 1, nrow = 1))  # set the legend position"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q3b",
    "href": "DANL310_midterm-spring-2023-a.html#q3b",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q3b",
    "text": "Q3b\n\nWhich zip_code does have the highest proportion of Pit Bull (or Mix)?\n\n\nq3b &lt;- fb_map %&gt;% \n  select(zip_code, breed_rc, pct) %&gt;% \n  filter(breed_rc == 'Pit Bull (or Mix)') %&gt;% \n  arrange(-pct) %&gt;% \n  distinct()"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q4a",
    "href": "DANL310_midterm-spring-2023-a.html#q4a",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q4a",
    "text": "Q4a\n\nReplicate the following ggplot.\n\n\n# Create a new variable year extracted from the Date column\nstock &lt;- stock %&gt;% \n  mutate(year = year(Date))\n\np &lt;- ggplot(data = filter(stock, year &gt;= 2019, year &lt;= 2022 ) , \n            aes(x = log(Volume), y = log(Close), color = company))\n\np + \n  geom_point(alpha = .05) +\n  geom_smooth(method = lm, color = 'black') +\n  facet_grid( company ~ year, scales = 'free' ) +\n  labs(x = 'Volume (in log)',\n       y = 'Close (in log)') +\n  guides(color = \"none\")"
  },
  {
    "objectID": "DANL310_midterm-spring-2023-a.html#q4b",
    "href": "DANL310_midterm-spring-2023-a.html#q4b",
    "title": "DANL 310: Data Visualization and Presentation Midterm Exam Example Answers",
    "section": "Q4b",
    "text": "Q4b\n\nIn 2020, which company’s stock trading Volume does seem to be the most insensitive to a change in Close price?\n\n\n# Create a new variable year extracted from the Date column\nstock &lt;- stock %&gt;% \n  mutate(year = year(Date))\n\np &lt;- ggplot(data = filter(stock, year &gt;= 2019, year &lt;= 2022 ) , \n            aes(x = log(Volume), y = log(Close), color = company))\n\np + \n  geom_point(alpha = .05) +\n  geom_smooth(method = lm, color = 'black') +\n  facet_grid( company ~ year ) +\n  labs(x = 'Volume (in log)',\n       y = 'Close (in log)') +\n  guides(color = \"none\")\n\n\n\n\n\nIn 2020, TSLA’s trading Volume seems to be the most insensitive to a change in Close price.\nThe reason is that for a one unit increase in log(Price), the least amount of log(Volume) changes for TSLA.\n\n\nreg &lt;- lm(log(Volume) ~ log(Close) * company,\n          data = filter(stock, year == 2020))\nreg_sum &lt;- tidy(reg, conf.int = T) %&gt;% \n  filter(str_detect(term, \"log\"), term != \"log(Close)\")\n\nggplot(reg_sum,\n       aes(x = estimate, y = term,\n           xmin = conf.low, \n           xmax = conf.high)) +\n  geom_point() +\n  geom_pointrange() +\n  geom_vline(xintercept = 0, color = 'red', lty = 2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jason Rappazzo",
    "section": "",
    "text": "I am a student at State University of New York at Geneseo.\nI am interested in …\nI enjoy …"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jason Rappazzo",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo, 2023 - B.A.in Economics - Minor in Data Analytics"
  },
  {
    "objectID": "table.html",
    "href": "table.html",
    "title": "Untitled",
    "section": "",
    "text": "kable(\n  iris,\n  col.names = c('We', 'Need', 'Five', 'Names', 'Here')\n) \n\n\n\n\nWe\nNeed\nFive\nNames\nHere\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.1\nsetosa\n\n\n5.4\n3.7\n1.5\n0.2\nsetosa\n\n\n4.8\n3.4\n1.6\n0.2\nsetosa\n\n\n4.8\n3.0\n1.4\n0.1\nsetosa\n\n\n4.3\n3.0\n1.1\n0.1\nsetosa\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.7\n4.4\n1.5\n0.4\nsetosa\n\n\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n5.1\n3.5\n1.4\n0.3\nsetosa\n\n\n5.7\n3.8\n1.7\n0.3\nsetosa\n\n\n5.1\n3.8\n1.5\n0.3\nsetosa\n\n\n5.4\n3.4\n1.7\n0.2\nsetosa\n\n\n5.1\n3.7\n1.5\n0.4\nsetosa\n\n\n4.6\n3.6\n1.0\n0.2\nsetosa\n\n\n5.1\n3.3\n1.7\n0.5\nsetosa\n\n\n4.8\n3.4\n1.9\n0.2\nsetosa\n\n\n5.0\n3.0\n1.6\n0.2\nsetosa\n\n\n5.0\n3.4\n1.6\n0.4\nsetosa\n\n\n5.2\n3.5\n1.5\n0.2\nsetosa\n\n\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.6\n0.2\nsetosa\n\n\n4.8\n3.1\n1.6\n0.2\nsetosa\n\n\n5.4\n3.4\n1.5\n0.4\nsetosa\n\n\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n5.5\n4.2\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.2\n1.2\n0.2\nsetosa\n\n\n5.5\n3.5\n1.3\n0.2\nsetosa\n\n\n4.9\n3.6\n1.4\n0.1\nsetosa\n\n\n4.4\n3.0\n1.3\n0.2\nsetosa\n\n\n5.1\n3.4\n1.5\n0.2\nsetosa\n\n\n5.0\n3.5\n1.3\n0.3\nsetosa\n\n\n4.5\n2.3\n1.3\n0.3\nsetosa\n\n\n4.4\n3.2\n1.3\n0.2\nsetosa\n\n\n5.0\n3.5\n1.6\n0.6\nsetosa\n\n\n5.1\n3.8\n1.9\n0.4\nsetosa\n\n\n4.8\n3.0\n1.4\n0.3\nsetosa\n\n\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n4.6\n3.2\n1.4\n0.2\nsetosa\n\n\n5.3\n3.7\n1.5\n0.2\nsetosa\n\n\n5.0\n3.3\n1.4\n0.2\nsetosa\n\n\n7.0\n3.2\n4.7\n1.4\nversicolor\n\n\n6.4\n3.2\n4.5\n1.5\nversicolor\n\n\n6.9\n3.1\n4.9\n1.5\nversicolor\n\n\n5.5\n2.3\n4.0\n1.3\nversicolor\n\n\n6.5\n2.8\n4.6\n1.5\nversicolor\n\n\n5.7\n2.8\n4.5\n1.3\nversicolor\n\n\n6.3\n3.3\n4.7\n1.6\nversicolor\n\n\n4.9\n2.4\n3.3\n1.0\nversicolor\n\n\n6.6\n2.9\n4.6\n1.3\nversicolor\n\n\n5.2\n2.7\n3.9\n1.4\nversicolor\n\n\n5.0\n2.0\n3.5\n1.0\nversicolor\n\n\n5.9\n3.0\n4.2\n1.5\nversicolor\n\n\n6.0\n2.2\n4.0\n1.0\nversicolor\n\n\n6.1\n2.9\n4.7\n1.4\nversicolor\n\n\n5.6\n2.9\n3.6\n1.3\nversicolor\n\n\n6.7\n3.1\n4.4\n1.4\nversicolor\n\n\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n5.8\n2.7\n4.1\n1.0\nversicolor\n\n\n6.2\n2.2\n4.5\n1.5\nversicolor\n\n\n5.6\n2.5\n3.9\n1.1\nversicolor\n\n\n5.9\n3.2\n4.8\n1.8\nversicolor\n\n\n6.1\n2.8\n4.0\n1.3\nversicolor\n\n\n6.3\n2.5\n4.9\n1.5\nversicolor\n\n\n6.1\n2.8\n4.7\n1.2\nversicolor\n\n\n6.4\n2.9\n4.3\n1.3\nversicolor\n\n\n6.6\n3.0\n4.4\n1.4\nversicolor\n\n\n6.8\n2.8\n4.8\n1.4\nversicolor\n\n\n6.7\n3.0\n5.0\n1.7\nversicolor\n\n\n6.0\n2.9\n4.5\n1.5\nversicolor\n\n\n5.7\n2.6\n3.5\n1.0\nversicolor\n\n\n5.5\n2.4\n3.8\n1.1\nversicolor\n\n\n5.5\n2.4\n3.7\n1.0\nversicolor\n\n\n5.8\n2.7\n3.9\n1.2\nversicolor\n\n\n6.0\n2.7\n5.1\n1.6\nversicolor\n\n\n5.4\n3.0\n4.5\n1.5\nversicolor\n\n\n6.0\n3.4\n4.5\n1.6\nversicolor\n\n\n6.7\n3.1\n4.7\n1.5\nversicolor\n\n\n6.3\n2.3\n4.4\n1.3\nversicolor\n\n\n5.6\n3.0\n4.1\n1.3\nversicolor\n\n\n5.5\n2.5\n4.0\n1.3\nversicolor\n\n\n5.5\n2.6\n4.4\n1.2\nversicolor\n\n\n6.1\n3.0\n4.6\n1.4\nversicolor\n\n\n5.8\n2.6\n4.0\n1.2\nversicolor\n\n\n5.0\n2.3\n3.3\n1.0\nversicolor\n\n\n5.6\n2.7\n4.2\n1.3\nversicolor\n\n\n5.7\n3.0\n4.2\n1.2\nversicolor\n\n\n5.7\n2.9\n4.2\n1.3\nversicolor\n\n\n6.2\n2.9\n4.3\n1.3\nversicolor\n\n\n5.1\n2.5\n3.0\n1.1\nversicolor\n\n\n5.7\n2.8\n4.1\n1.3\nversicolor\n\n\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n7.1\n3.0\n5.9\n2.1\nvirginica\n\n\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n6.5\n3.0\n5.8\n2.2\nvirginica\n\n\n7.6\n3.0\n6.6\n2.1\nvirginica\n\n\n4.9\n2.5\n4.5\n1.7\nvirginica\n\n\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n6.7\n2.5\n5.8\n1.8\nvirginica\n\n\n7.2\n3.6\n6.1\n2.5\nvirginica\n\n\n6.5\n3.2\n5.1\n2.0\nvirginica\n\n\n6.4\n2.7\n5.3\n1.9\nvirginica\n\n\n6.8\n3.0\n5.5\n2.1\nvirginica\n\n\n5.7\n2.5\n5.0\n2.0\nvirginica\n\n\n5.8\n2.8\n5.1\n2.4\nvirginica\n\n\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n6.5\n3.0\n5.5\n1.8\nvirginica\n\n\n7.7\n3.8\n6.7\n2.2\nvirginica\n\n\n7.7\n2.6\n6.9\n2.3\nvirginica\n\n\n6.0\n2.2\n5.0\n1.5\nvirginica\n\n\n6.9\n3.2\n5.7\n2.3\nvirginica\n\n\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n7.7\n2.8\n6.7\n2.0\nvirginica\n\n\n6.3\n2.7\n4.9\n1.8\nvirginica\n\n\n6.7\n3.3\n5.7\n2.1\nvirginica\n\n\n7.2\n3.2\n6.0\n1.8\nvirginica\n\n\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n6.4\n2.8\n5.6\n2.1\nvirginica\n\n\n7.2\n3.0\n5.8\n1.6\nvirginica\n\n\n7.4\n2.8\n6.1\n1.9\nvirginica\n\n\n7.9\n3.8\n6.4\n2.0\nvirginica\n\n\n6.4\n2.8\n5.6\n2.2\nvirginica\n\n\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n6.1\n2.6\n5.6\n1.4\nvirginica\n\n\n7.7\n3.0\n6.1\n2.3\nvirginica\n\n\n6.3\n3.4\n5.6\n2.4\nvirginica\n\n\n6.4\n3.1\n5.5\n1.8\nvirginica\n\n\n6.0\n3.0\n4.8\n1.8\nvirginica\n\n\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n\n\n\n\nknitr::kable(iris, align = \"lccrr\")\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.1\nsetosa\n\n\n5.4\n3.7\n1.5\n0.2\nsetosa\n\n\n4.8\n3.4\n1.6\n0.2\nsetosa\n\n\n4.8\n3.0\n1.4\n0.1\nsetosa\n\n\n4.3\n3.0\n1.1\n0.1\nsetosa\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.7\n4.4\n1.5\n0.4\nsetosa\n\n\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n5.1\n3.5\n1.4\n0.3\nsetosa\n\n\n5.7\n3.8\n1.7\n0.3\nsetosa\n\n\n5.1\n3.8\n1.5\n0.3\nsetosa\n\n\n5.4\n3.4\n1.7\n0.2\nsetosa\n\n\n5.1\n3.7\n1.5\n0.4\nsetosa\n\n\n4.6\n3.6\n1.0\n0.2\nsetosa\n\n\n5.1\n3.3\n1.7\n0.5\nsetosa\n\n\n4.8\n3.4\n1.9\n0.2\nsetosa\n\n\n5.0\n3.0\n1.6\n0.2\nsetosa\n\n\n5.0\n3.4\n1.6\n0.4\nsetosa\n\n\n5.2\n3.5\n1.5\n0.2\nsetosa\n\n\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.6\n0.2\nsetosa\n\n\n4.8\n3.1\n1.6\n0.2\nsetosa\n\n\n5.4\n3.4\n1.5\n0.4\nsetosa\n\n\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n5.5\n4.2\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.2\n1.2\n0.2\nsetosa\n\n\n5.5\n3.5\n1.3\n0.2\nsetosa\n\n\n4.9\n3.6\n1.4\n0.1\nsetosa\n\n\n4.4\n3.0\n1.3\n0.2\nsetosa\n\n\n5.1\n3.4\n1.5\n0.2\nsetosa\n\n\n5.0\n3.5\n1.3\n0.3\nsetosa\n\n\n4.5\n2.3\n1.3\n0.3\nsetosa\n\n\n4.4\n3.2\n1.3\n0.2\nsetosa\n\n\n5.0\n3.5\n1.6\n0.6\nsetosa\n\n\n5.1\n3.8\n1.9\n0.4\nsetosa\n\n\n4.8\n3.0\n1.4\n0.3\nsetosa\n\n\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n4.6\n3.2\n1.4\n0.2\nsetosa\n\n\n5.3\n3.7\n1.5\n0.2\nsetosa\n\n\n5.0\n3.3\n1.4\n0.2\nsetosa\n\n\n7.0\n3.2\n4.7\n1.4\nversicolor\n\n\n6.4\n3.2\n4.5\n1.5\nversicolor\n\n\n6.9\n3.1\n4.9\n1.5\nversicolor\n\n\n5.5\n2.3\n4.0\n1.3\nversicolor\n\n\n6.5\n2.8\n4.6\n1.5\nversicolor\n\n\n5.7\n2.8\n4.5\n1.3\nversicolor\n\n\n6.3\n3.3\n4.7\n1.6\nversicolor\n\n\n4.9\n2.4\n3.3\n1.0\nversicolor\n\n\n6.6\n2.9\n4.6\n1.3\nversicolor\n\n\n5.2\n2.7\n3.9\n1.4\nversicolor\n\n\n5.0\n2.0\n3.5\n1.0\nversicolor\n\n\n5.9\n3.0\n4.2\n1.5\nversicolor\n\n\n6.0\n2.2\n4.0\n1.0\nversicolor\n\n\n6.1\n2.9\n4.7\n1.4\nversicolor\n\n\n5.6\n2.9\n3.6\n1.3\nversicolor\n\n\n6.7\n3.1\n4.4\n1.4\nversicolor\n\n\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n5.8\n2.7\n4.1\n1.0\nversicolor\n\n\n6.2\n2.2\n4.5\n1.5\nversicolor\n\n\n5.6\n2.5\n3.9\n1.1\nversicolor\n\n\n5.9\n3.2\n4.8\n1.8\nversicolor\n\n\n6.1\n2.8\n4.0\n1.3\nversicolor\n\n\n6.3\n2.5\n4.9\n1.5\nversicolor\n\n\n6.1\n2.8\n4.7\n1.2\nversicolor\n\n\n6.4\n2.9\n4.3\n1.3\nversicolor\n\n\n6.6\n3.0\n4.4\n1.4\nversicolor\n\n\n6.8\n2.8\n4.8\n1.4\nversicolor\n\n\n6.7\n3.0\n5.0\n1.7\nversicolor\n\n\n6.0\n2.9\n4.5\n1.5\nversicolor\n\n\n5.7\n2.6\n3.5\n1.0\nversicolor\n\n\n5.5\n2.4\n3.8\n1.1\nversicolor\n\n\n5.5\n2.4\n3.7\n1.0\nversicolor\n\n\n5.8\n2.7\n3.9\n1.2\nversicolor\n\n\n6.0\n2.7\n5.1\n1.6\nversicolor\n\n\n5.4\n3.0\n4.5\n1.5\nversicolor\n\n\n6.0\n3.4\n4.5\n1.6\nversicolor\n\n\n6.7\n3.1\n4.7\n1.5\nversicolor\n\n\n6.3\n2.3\n4.4\n1.3\nversicolor\n\n\n5.6\n3.0\n4.1\n1.3\nversicolor\n\n\n5.5\n2.5\n4.0\n1.3\nversicolor\n\n\n5.5\n2.6\n4.4\n1.2\nversicolor\n\n\n6.1\n3.0\n4.6\n1.4\nversicolor\n\n\n5.8\n2.6\n4.0\n1.2\nversicolor\n\n\n5.0\n2.3\n3.3\n1.0\nversicolor\n\n\n5.6\n2.7\n4.2\n1.3\nversicolor\n\n\n5.7\n3.0\n4.2\n1.2\nversicolor\n\n\n5.7\n2.9\n4.2\n1.3\nversicolor\n\n\n6.2\n2.9\n4.3\n1.3\nversicolor\n\n\n5.1\n2.5\n3.0\n1.1\nversicolor\n\n\n5.7\n2.8\n4.1\n1.3\nversicolor\n\n\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n7.1\n3.0\n5.9\n2.1\nvirginica\n\n\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n6.5\n3.0\n5.8\n2.2\nvirginica\n\n\n7.6\n3.0\n6.6\n2.1\nvirginica\n\n\n4.9\n2.5\n4.5\n1.7\nvirginica\n\n\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n6.7\n2.5\n5.8\n1.8\nvirginica\n\n\n7.2\n3.6\n6.1\n2.5\nvirginica\n\n\n6.5\n3.2\n5.1\n2.0\nvirginica\n\n\n6.4\n2.7\n5.3\n1.9\nvirginica\n\n\n6.8\n3.0\n5.5\n2.1\nvirginica\n\n\n5.7\n2.5\n5.0\n2.0\nvirginica\n\n\n5.8\n2.8\n5.1\n2.4\nvirginica\n\n\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n6.5\n3.0\n5.5\n1.8\nvirginica\n\n\n7.7\n3.8\n6.7\n2.2\nvirginica\n\n\n7.7\n2.6\n6.9\n2.3\nvirginica\n\n\n6.0\n2.2\n5.0\n1.5\nvirginica\n\n\n6.9\n3.2\n5.7\n2.3\nvirginica\n\n\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n7.7\n2.8\n6.7\n2.0\nvirginica\n\n\n6.3\n2.7\n4.9\n1.8\nvirginica\n\n\n6.7\n3.3\n5.7\n2.1\nvirginica\n\n\n7.2\n3.2\n6.0\n1.8\nvirginica\n\n\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n6.4\n2.8\n5.6\n2.1\nvirginica\n\n\n7.2\n3.0\n5.8\n1.6\nvirginica\n\n\n7.4\n2.8\n6.1\n1.9\nvirginica\n\n\n7.9\n3.8\n6.4\n2.0\nvirginica\n\n\n6.4\n2.8\n5.6\n2.2\nvirginica\n\n\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n6.1\n2.6\n5.6\n1.4\nvirginica\n\n\n7.7\n3.0\n6.1\n2.3\nvirginica\n\n\n6.3\n3.4\n5.6\n2.4\nvirginica\n\n\n6.4\n3.1\n5.5\n1.8\nvirginica\n\n\n6.0\n3.0\n4.8\n1.8\nvirginica\n\n\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n\n\n\n\nd &lt;- cbind(X1 = runif(3), X2 = 10^c(3, 5, 7), X3 = rnorm(3,\n  0, 1000))\n# at most 4 decimal places\nknitr::kable(d, digits = 4)\n\n\n\n\nX1\nX2\nX3\n\n\n\n\n0.6666\n1e+03\n497.7155\n\n\n0.0821\n1e+05\n198.8978\n\n\n0.5323\n1e+07\n1709.2904\n\n\n\n\n\n\n\n\nknitr::kable(d, digits = 3, \n             format.args = list(scientific = FALSE))\n\n\n\n\nX1\nX2\nX3\n\n\n\n\n0.667\n1000\n497.715\n\n\n0.082\n100000\n198.898\n\n\n0.532\n10000000\n1709.290"
  }
]